{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "This notebook can be used to assess any keras model with the following evaluations:\n",
    "* [Visual](#Visual)\n",
    "* [Classification Report](#Classification_Report)\n",
    "* [ROC curve](#ROC_curve)\n",
    "\n",
    "It does not asses the training phase - this should be done in the model training notebooks.\n",
    "\n",
    "## How to use\n",
    "First adjust the code in the Preperations section to load the desired model and test data set.\n",
    "\n",
    "## Preperations\n",
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tf.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, plot_roc_curve, \\\n",
    "    precision_recall_curve, average_precision_score\n",
    "import preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = ...\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = preprocess.labeled_data(\n",
    "    'practice_images/multi_category/test/raw/', \n",
    "    'practice_images/multi_category/test/annot/', \n",
    "    resize=(480, 480))\n",
    "\n",
    "print(f'X_test shape = {X_test.shape}\\ny_test shape = {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('background', 'class1', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Predictions with the model__\n",
    "* Store categorical predictions in `y_pred`\n",
    "* Combine prediction channels into a single channel `y_pred_combined`.  Note that this is a simple combination method that assigns the class of the pixel to the channel with the highest probability prediction.  More acurate models may be possible if they take different approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "def combine(array):\n",
    "    rtn_array = np.zeros_like(array[:, :, :, 0])\n",
    "    for batch, _ in enumerate(array):\n",
    "        for row, _ in enumerate(array[0]):\n",
    "            for column, _ in enumerate(array[0, 0]):\n",
    "                rtn_array[batch, row, column] = array[batch, row, column, :].argmax()\n",
    "    return rtn_array\n",
    "\n",
    "\n",
    "def combine_advanced(array, channel, thresh):\n",
    "    rtn_array = np.zeros_like(array[:, :, :, 0])\n",
    "    for batch, _ in enumerate(array):\n",
    "        for row, _ in enumerate(array[0]):\n",
    "            for column, _ in enumerate(array[0, 0]):\n",
    "                if array[batch, row, column, channel] > thresh:\n",
    "                    rtn_array[batch, row, column] = channel\n",
    "                else:\n",
    "                    rtn_array[batch, row, column] = array[batch, row, column, :].argmax()\n",
    "    return rtn_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual\n",
    "\n",
    "### All classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xzoom, yzoom = [(None, None), (None, None)], [(None, None), (None, None)]\n",
    "titles = ['original', 'ground truth', 'prediction']\n",
    "images = [X_test, combine(y_test), combine(y_pred)]\n",
    "\n",
    "for i, _ in enumerate(X_test):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for plot, (title, image) in enumerate(zip(titles, images)):\n",
    "        plt.subplot(1, 3, plot+1)\n",
    "        plt.imshow(image[i])\n",
    "        plt.title(title)\n",
    "        plt.xlim(xzoom[i]); plt.ylim(yzoom[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defect class only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter defect class and zooms as required\n",
    "defect_class = 2\n",
    "xzoom, yzoom = [(260, 325), (210, 310)], [(220, 160), (300, 200)]\n",
    "\n",
    "titles = ['original', 'ground truth', 'prediction']\n",
    "images = [X_test, y_test[:, :, :, defect_class], y_pred[:, :, :, defect_class]]\n",
    "\n",
    "print(f'Probability predictions for {classes[defect_class]} class')\n",
    "\n",
    "for i, _ in enumerate(X_test):\n",
    "    plt.figure(figsize=(17, 5))\n",
    "    for plot, (title, image) in enumerate(zip(titles, images)):\n",
    "        plt.subplot(1, 3, plot+1)\n",
    "        plt.imshow(image[i])\n",
    "        plt.title(title)\n",
    "        plt.xlim(xzoom[i]); plt.ylim(yzoom[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification_Report\n",
    "This should be run on a combined (single channel) image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        combine(y_test).ravel(),\n",
    "        combine(y_pred).ravel(),\n",
    "        target_names=classes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC_curve\n",
    "\n",
    "### On class specific channels\n",
    "Below the roc curve is shown for each channel __when considered individualy__.  This is not representitive of a combined image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aocs = []\n",
    "\n",
    "plt.figure(figsize=(16, 7))\n",
    "plt.suptitle(f'ROC curve (specific channel) for   {model_path.split(\"/\")[-1]}', size='x-large')\n",
    "\n",
    "plt.subplot(121)\n",
    "for cls, name in enumerate(classes):\n",
    "    aoc = roc_auc_score( y_test[:, :, :, cls].ravel(), y_pred[:, :, :, cls].ravel() )\n",
    "    aocs.append(aoc)\n",
    "    fpr, tpr, thresholds = roc_curve( y_test[:, :, :, cls].ravel(), y_pred[:, :, :, cls].ravel() )\n",
    "    plt.plot(fpr, tpr, label=f'{name}  AOC = {aoc:.3f}')\n",
    "plt.plot([0, 1], [0, 1], ls='--', c='r')\n",
    "plt.title(f'ROC curve')\n",
    "plt.xlabel('false positive rate'); plt.ylabel('true positive rate')\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.bar(classes, aocs, color=plt.rcParams['axes.prop_cycle'].by_key()['color'], alpha=0.9)\n",
    "plt.title('AUC scores')\n",
    "plt.ylim(0.9, 1.01)\n",
    "plt.xticks(rotation=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall_curve\n",
    "\n",
    "### On class specific channels\n",
    "Below the precision-recall curve is shown for each channel __when considered individualy__.  This is not representitive of a combined image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aps = []\n",
    "\n",
    "plt.figure(figsize=(16, 7))\n",
    "plt.suptitle(f'Precision-Recall curve (specific channel) for   {model_path.split(\"/\")[-1]}', size='x-large')\n",
    "\n",
    "plt.subplot(121)\n",
    "for cls, name in enumerate(classes):\n",
    "    ap = average_precision_score( y_test[:, :, :, cls].ravel(), y_pred[:, :, :, cls].ravel() )\n",
    "    aps.append(ap)\n",
    "    precision, recall, thresholds = precision_recall_curve( y_test[:, :, :, cls].ravel(), y_pred[:, :, :, cls].ravel() )\n",
    "    plt.plot(recall, precision, label=f'{name}  AP = {ap:.3f}')\n",
    "plt.plot([0, 1], [0, 1], ls='--', c='r')\n",
    "plt.title(f'Curves')\n",
    "plt.xlabel('recall'); plt.ylabel('precision')\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.legend(loc='lower center')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.bar(classes, aps, color=plt.rcParams['axes.prop_cycle'].by_key()['color'], alpha=0.9)\n",
    "plt.title('Scores')\n",
    "# plt.ylim(0.9, 1.01)\n",
    "plt.xticks(rotation=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On combined image\n",
    "The roc curve below is for the binary recocnition of a defect class **from the combined image**.  Note this requires an advanced function to be used for combining which applied a threshold for identification of the defect class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshs = np.linspace(0, 1, 1000)\n",
    "\n",
    "\n",
    "(combine_advanced(y_pred, 1, 0.1) == True) == combine(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
